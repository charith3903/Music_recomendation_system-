{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c66f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "# Only for the app.py part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "157654d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Head:\n",
      "         username                track_id    track_name    track_artist  \\\n",
      "0  cassandrakline  697MjF1454XKvZmTuqkWmD    I Miss You          Jeriqo   \n",
      "1         ebutler  3x2bXiU0o4WbsPkawXlfDA   Who Are You         The Who   \n",
      "2     gravesaaron  0jEaPBjFAWjQTMVouRwaHi         Happy  The Beef Seeds   \n",
      "3        nathan50  5EKUb1FKsyYVaSXb41YBIj           ONE      Rev Theory   \n",
      "4          mjones  300DUx4tdtCdGEUXR032jA  Palace/Curse    The Internet   \n",
      "\n",
      "   track_popularity          track_album_id          track_album_name  \\\n",
      "0                45  2vJ6FDg6ZMS56U8Wbiw2Oz                I Miss You   \n",
      "1                17  6LRJF97hgXHj8uMLHyCDbh  Who Are You (Remastered)   \n",
      "2                30  4IQn9XpweytNX2cUe2NBUH          Keepin' it Beefy   \n",
      "3                35  0gGic19XvEiHKKWBV7M4YM                       ONE   \n",
      "4                62  69g3CtOVg98TPOwqmI2K7Q                 Ego Death   \n",
      "\n",
      "  track_album_release_date            playlist_name             playlist_id  \\\n",
      "0                 2/5/2019       Pop Hits 2000-2019  6mtYuOxzl58vSGnEDtZ9uB   \n",
      "1                8/18/1978  House Of The Rising Sun  1bMYfBHYBCRHY5LGkjlpSy   \n",
      "2                1/19/2015         Bluegrass Covers  37i9dQZF1DX56crgoe4TG3   \n",
      "3                1/15/2020                Rock Hard  37i9dQZF1DWWJOmJ7nRx0C   \n",
      "4                6/26/2015                 NEO-soul  3q3M4VCymcMoxJ3Tl7mRqN   \n",
      "\n",
      "   ... speechiness acousticness  instrumentalness  liveness  valence    tempo  \\\n",
      "0  ...      0.0432     0.004910          0.000013    0.0816    0.415  174.026   \n",
      "1  ...      0.0511     0.265000          0.003130    0.1060    0.489  156.371   \n",
      "2  ...      0.1600     0.665000          0.000000    0.1270    0.932   86.529   \n",
      "3  ...      0.0453     0.000006          0.000000    0.3030    0.520   90.016   \n",
      "4  ...      0.3230     0.035100          0.000727    0.2430    0.261   67.104   \n",
      "\n",
      "   duration_ms   activity    location  time_of_day  \n",
      "0       216347  commuting  in transit      morning  \n",
      "1       378707   relaxing      office      evening  \n",
      "2       218044   relaxing         gym    afternoon  \n",
      "3       208196   studying      office    afternoon  \n",
      "4       440013  commuting      office    afternoon  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Shape: (1000, 27)\n",
      "\n",
      "Columns: ['username', 'track_id', 'track_name', 'track_artist', 'track_popularity', 'track_album_id', 'track_album_name', 'track_album_release_date', 'playlist_name', 'playlist_id', 'playlist_genre', 'playlist_subgenre', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'activity', 'location', 'time_of_day']\n",
      "\n",
      "Missing values:\n",
      " username                    0\n",
      "track_id                    0\n",
      "track_name                  0\n",
      "track_artist                0\n",
      "track_popularity            0\n",
      "track_album_id              0\n",
      "track_album_name            0\n",
      "track_album_release_date    0\n",
      "playlist_name               0\n",
      "playlist_id                 0\n",
      "playlist_genre              0\n",
      "playlist_subgenre           0\n",
      "danceability                0\n",
      "energy                      0\n",
      "key                         0\n",
      "loudness                    0\n",
      "mode                        0\n",
      "speechiness                 0\n",
      "acousticness                0\n",
      "instrumentalness            0\n",
      "liveness                    0\n",
      "valence                     0\n",
      "tempo                       0\n",
      "duration_ms                 0\n",
      "activity                    0\n",
      "location                    0\n",
      "time_of_day                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Load Data ---\n",
    "url = \"https://raw.githubusercontent.com/charith3903/context-aware-music-recommender/refs/heads/main/contextual_spotify_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Original Data Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "732a1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Feature Engineering and Preprocessing ---\n",
    "label_cols = ['activity', 'location', 'time_of_day', 'username']\n",
    "encoders = {}\n",
    "\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a5c9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a mapping of encoded track_name to original track_name for recommendations\n",
    "# We need to encode 'track_name' to use it as a 'class' if we were doing classification,\n",
    "# but for similarity, we just need its original value for output.\n",
    "# However, we will use it for inverse transformation in the recommendation function.\n",
    "track_name_encoder = LabelEncoder()\n",
    "df['track_name_encoded'] = track_name_encoder.fit_transform(df['track_name'])\n",
    "encoders['track_name'] = track_name_encoder # Store it for later decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bf17c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['tempo', 'energy', 'valence', 'danceability', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']\n",
    "context_features = ['activity', 'location', 'time_of_day']\n",
    "user_feature = ['username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "184ddc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all features for the recommendation engine\n",
    "all_features_for_recommendation = context_features + numeric_features + user_feature\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "joblib.dump(scaler, 'scaler.pkl') # Save the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8a32f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed data and encoders saved successfully.\n",
      "\n",
      "Unique activities (after encoding): [0 2 3 4 1]\n",
      "Unique locations (after encoding): [2 3 0 1 4]\n",
      "Unique times (after encoding): [2 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Save Processed Data and Encoders ---\n",
    "# We no longer train a RandomForestClassifier for direct 'track_name' prediction.\n",
    "# Instead, we'll use the processed DataFrame and encoders for similarity-based recommendations.\n",
    "joblib.dump(df[all_features_for_recommendation], 'processed_features.pkl')\n",
    "joblib.dump(df['track_name'], 'original_track_names.pkl')\n",
    "joblib.dump(encoders, 'encoders.pkl')\n",
    "\n",
    "print(\"\\nProcessed data and encoders saved successfully.\")\n",
    "print(\"\\nUnique activities (after encoding):\", df['activity'].unique())\n",
    "print(\"Unique locations (after encoding):\", df['location'].unique())\n",
    "print(\"Unique times (after encoding):\", df['time_of_day'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09d2ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Recommendation Function ---\n",
    "def recommend_playlist(activity, location, time_of_day, tempo, energy, valence, danceability, speechiness, acousticness, instrumentalness, liveness, username=None, top_n=5):\n",
    "    # Load necessary components within the function for a standalone script/app\n",
    "    try:\n",
    "        loaded_encoders = joblib.load('encoders.pkl')\n",
    "        loaded_processed_features = joblib.load('processed_features.pkl')\n",
    "        loaded_original_track_names = joblib.load('original_track_names.pkl')\n",
    "        loaded_scaler = joblib.load('scaler.pkl')\n",
    "    except FileNotFoundError:\n",
    "        return [\"Error: Model files not found. Please run the full script to generate them.\"]\n",
    "\n",
    "    try:\n",
    "        # Encode categorical inputs\n",
    "        encoded_activity = loaded_encoders['activity'].transform([activity])[0]\n",
    "        encoded_location = loaded_encoders['location'].transform([location])[0]\n",
    "        encoded_time_of_day = loaded_encoders['time_of_day'].transform([time_of_day])[0]\n",
    "\n",
    "        # Handle unknown username: assign a default value (e.g., 0)\n",
    "        if username and username in loaded_encoders['username'].classes_:\n",
    "            encoded_username = loaded_encoders['username'].transform([username])[0]\n",
    "        else:\n",
    "            encoded_username = 0 # Default for unknown users or no username provided\n",
    "\n",
    "        # Create a DataFrame for the single user input\n",
    "        user_input_df = pd.DataFrame([{\n",
    "            'activity': encoded_activity,\n",
    "            'location': encoded_location,\n",
    "            'time_of_day': encoded_time_of_day,\n",
    "            'tempo': tempo,\n",
    "            'energy': energy,\n",
    "            'valence': valence,\n",
    "            'danceability': danceability,\n",
    "            'speechiness': speechiness,\n",
    "            'acousticness': acousticness,\n",
    "            'instrumentalness': instrumentalness,\n",
    "            'liveness': liveness,\n",
    "            'username': encoded_username\n",
    "        }])\n",
    "\n",
    "        # Scale the numeric features of the user input\n",
    "        numeric_cols_user_input = ['tempo', 'energy', 'valence', 'danceability', 'speechiness', 'acousticness', 'instrumentalness', 'liveness']\n",
    "        user_input_df[numeric_cols_user_input] = loaded_scaler.transform(user_input_df[numeric_cols_user_input])\n",
    "\n",
    "        # Calculate cosine similarity between user input and all songs in the dataset\n",
    "        # Ensure column order matches\n",
    "        dataset_features = loaded_processed_features[all_features_for_recommendation]\n",
    "        similarities = cosine_similarity(user_input_df, dataset_features)\n",
    "\n",
    "        # Get top N song indices based on similarity\n",
    "        # Use .flatten() because cosine_similarity returns a 2D array\n",
    "        top_n_indices = np.argsort(similarities.flatten())[::-1][:top_n]\n",
    "\n",
    "        # Get the original track names corresponding to the top indices\n",
    "        recommended_songs = loaded_original_track_names.iloc[top_n_indices].tolist()\n",
    "\n",
    "        return recommended_songs\n",
    "\n",
    "    except ValueError as e:\n",
    "        return [f\"‚ùå Error: {str(e)}. Make sure your input values are valid for the selected categories.\"]\n",
    "    except Exception as e:\n",
    "        return [f\"An unexpected error occurred: {str(e)}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d942f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Recommendation Function ---\n",
      "\n",
      "üéß Playlist for new user (exercising in gym, morning):\n",
      "1. Symphony (feat. Zara Larsson)\n",
      "2. Dancin (feat. Luvli) - Krono Remix\n",
      "3. Love\n",
      "4. Can't Back Down\n",
      "5. Used To Love (with Dean Lewis)\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Test the Recommendation Function ---\n",
    "print(\"\\n--- Testing Recommendation Function ---\")\n",
    "\n",
    "print(\"\\nüéß Playlist for new user (exercising in gym, morning):\")\n",
    "playlist_new_user = recommend_playlist(\n",
    "    activity=\"exercising\",\n",
    "    location=\"gym\",\n",
    "    time_of_day=\"morning\",\n",
    "    tempo=130,\n",
    "    energy=0.9,\n",
    "    valence=0.7,\n",
    "    danceability=0.8,\n",
    "    speechiness=0.05,\n",
    "    acousticness=0.1,\n",
    "    instrumentalness=0.001,\n",
    "    liveness=0.15,\n",
    "    top_n=5\n",
    ")\n",
    "for i, song in enumerate(playlist_new_user, 1):\n",
    "    print(f\"{i}. {song}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47ddf9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéß Playlist for existing user (studying in office, evening, username 'mjones'):\n",
      "1. Girl\n",
      "2. Changes - 2015 Remaster\n",
      "3. It's You\n",
      "4. As It Sets\n",
      "5. Stranger\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüéß Playlist for existing user (studying in office, evening, username 'mjones'):\")\n",
    "playlist_old_user = recommend_playlist(\n",
    "    activity=\"studying\",\n",
    "    location=\"office\",\n",
    "    time_of_day=\"evening\",\n",
    "    tempo=100,\n",
    "    energy=0.4,\n",
    "    valence=0.3,\n",
    "    danceability=0.5,\n",
    "    speechiness=0.1,\n",
    "    acousticness=0.5,\n",
    "    instrumentalness=0.01,\n",
    "    liveness=0.1,\n",
    "    username=\"mjones\", # Use an existing username from your dataset for a more realistic test\n",
    "    top_n=5\n",
    ")\n",
    "for i, song in enumerate(playlist_old_user, 1):\n",
    "    print(f\"{i}. {song}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfc64c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Content-Based Recommender (Hit Rate@K) ---\n",
      "\n",
      "Hit Rate@5: 1.0000 (meaning 200 out of 200 actual songs were found in the top 5 recommendations)\n"
     ]
    }
   ],
   "source": [
    "# --- NEW: Evaluation for Content-Based Recommender ---\n",
    "print(\"\\n--- Evaluating Content-Based Recommender (Hit Rate@K) ---\")\n",
    "\n",
    "# We'll simulate user interactions by taking existing data points as \"true\" preferences.\n",
    "# For simplicity, let's use a small subset of the original dataframe as our \"test set\" for evaluation.\n",
    "# In a real-world scenario, you'd want a separate held-out test set of user-item interactions.\n",
    "\n",
    "# Split data to simulate evaluation on unseen (but known) instances\n",
    "# Note: For content-based, the \"training\" is essentially creating the feature vectors,\n",
    "# so the train/test split here is more for evaluating the *recommendation process*\n",
    "# on data points not used to \"build\" the feature space.\n",
    "_, df_eval = train_test_split(df, test_size=0.2, random_state=42) # Use df here, not X, y directly\n",
    "\n",
    "top_k = 5\n",
    "hits = 0\n",
    "\n",
    "# It's important to use the original, unscaled values from df_eval to pass to recommend_playlist\n",
    "# and let the function handle encoding/scaling internally as it would for a new user input.\n",
    "for index, row in df_eval.iterrows():\n",
    "    actual_track_name = row['track_name']\n",
    "    recommended_songs = recommend_playlist(\n",
    "        activity=encoders['activity'].inverse_transform([row['activity']])[0],\n",
    "        location=encoders['location'].inverse_transform([row['location']])[0],\n",
    "        time_of_day=encoders['time_of_day'].inverse_transform([row['time_of_day']])[0],\n",
    "        tempo=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][0], # Inverse scale for input\n",
    "        energy=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][1],\n",
    "        valence=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][2],\n",
    "        danceability=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][3],\n",
    "        speechiness=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][4],\n",
    "        acousticness=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][5],\n",
    "        instrumentalness=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][6],\n",
    "        liveness=scaler.inverse_transform(row[numeric_features].values.reshape(1, -1))[0][7],\n",
    "        username=encoders['username'].inverse_transform([row['username']])[0],\n",
    "        top_n=top_k\n",
    "    )\n",
    "\n",
    "    if actual_track_name in recommended_songs:\n",
    "        hits += 1\n",
    "\n",
    "hit_rate = hits / len(df_eval)\n",
    "print(f\"\\nHit Rate@{top_k}: {hit_rate:.4f} (meaning {hits} out of {len(df_eval)} actual songs were found in the top {top_k} recommendations)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ee8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
